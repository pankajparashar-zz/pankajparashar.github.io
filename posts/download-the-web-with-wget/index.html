<!DOCTYPE html><html dir=ltr lang=en-US class=no-js><head><!-- | Character Encoding |
        ===========================
        1. Authors are encouraged to use UTF-8, as its the most friendly for internationalization.
        2. This <meta> element must be inside the <head> element within the first-512 bytes of the page. --><meta charset=utf-8><!-- | HTML5 Link Prefetch |
        ============================
        Link prefetching is a browser mechanism, which utilizes browser idle time to download or prefetch
        documents that the user might visit in the near future.
        Prerender : Identifies a webpage to load in the background, in case the user wants to navigate to it next
        Prefetch : Identifies a resource file, such as an image or a CSS stylesheet, to be downloaded into the cache
        DNS-Prefetch : Identifies a DNS query to resolve the background, so that requests can occur more quickly --><link rel=dns-prefetch href=//ajax.googleapis.com><link rel=dns-prefetch href=//res.cloudinary.com><link rel=prerender href=//pankajparashar.com/projects><!-- | Flip ahead browsing |
        ============================
        Flip ahead allows you to explore favorite websites like you would a magazine. --><link rel=next href=/page/2><link rel=prev href="/"><!-- | Internet Explorer Meta Header |
        ======================================
        The X-UA-Compatible meta tag allows web authors to choose what version of Internet Explorer the
        page should be rendered as. Edge mode tells Internet Explorer to display content in the highest
        mode available. --><meta http-equiv=X-UA-Compatible content="IE=edge"><!--
          For blog posts - use the title of the article
          else - use the default title.
        --><title>Download the web with WGET - by Pankaj Parashar</title><!-- | SEO Meta Tag |
        =====================
        A page's descriptionription meta tag gives Google and other search engines a summary of what the page is about.
        Source : Google's Search Engine Optimisation Guide (PDF) --><meta name=description content="Hello. I am Pankaj Parashar, a 24yrs old front-end designer and web developer from Mumbai, India."><!-- | Mobile Viewport Meta Tag |
        =================================
        device-width  = Occupy full width of the screen in its current orientation
        initial-scale = 1.0 retains dimensions instead of zooming out if page height > device height
        maximum-scale = 1.0 retains dimensions instead of zooming in if page width < device width
        minimal-ui = iOS7.1 full screen mode --><meta name=viewport content="width=device-width, initial-scale=1, minimal-ui"><!-- | Stylesheet |
        ===================
        normalize.css : Modern day alternative to CSS resets by Nicolas Galagher/Jonathan Neal
        style.css : Site specific stylesheet --><link rel=stylesheet href=/css/main.d15b.css><!--<link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/font-awesome/4.0.3/css/font-awesome.min.css">--><!-- | Favicons |
        =================
        Generated using Real Favicon Generator
        Source : realfavicongenerator.net --><link rel=apple-touch-icon sizes=57x57 href=apple-touch-icon-57x57.png><link rel=apple-touch-icon sizes=114x114 href=apple-touch-icon-114x114.png><link rel=apple-touch-icon sizes=72x72 href=apple-touch-icon-72x72.png><link rel=apple-touch-icon sizes=144x144 href=apple-touch-icon-144x144.png><link rel=apple-touch-icon sizes=60x60 href=apple-touch-icon-60x60.png><link rel=apple-touch-icon sizes=120x120 href=apple-touch-icon-120x120.png><link rel=apple-touch-icon sizes=76x76 href=apple-touch-icon-76x76.png><link rel=apple-touch-icon sizes=152x152 href=apple-touch-icon-152x152.png><link rel=icon type=image/png href=favicon-16x16.png sizes=16x16><link rel=icon type=image/png href=favicon-32x32.png sizes=32x32><link rel=icon type=image/png href=favicon-96x96.png sizes=96x96><link rel=icon type=image/png href=favicon-160x160.png sizes=160x160><!-- | Windows 8 Metro UI Tiles |
        =================================
        Generated using Modern IE
        Source : buildmypinnedsite.com --><meta name=application-name content="Pankaj Parashar"><meta name=msapplication-TileColor content=#ffc40d><meta name=msapplication-TileImage content=mstile-144x144.png><meta name=msapplication-square70x70logo content=mstile-70x70.png><meta name=msapplication-square150x150logo content=mstile-150x150.png><meta name=msapplication-square310x310logo content=mstile-310x310.png><!-- | Twitter Cards |
        ======================
        Validator : dev.twitter.com/docs/cards/validation/validator --><meta name=twitter:card content=summary><meta name=twitter:site content=@pankajparashar><meta name=twitter:title content="Pankaj Parashar"><meta name=twitter:description content="Developer. Designer. Writer."><meta name=twitter:creator content=@pankajparashar><meta name=twitter:image:src content=http://pankajparashar.com/img/logo.png><meta name=twitter:domain content=pankajparashar.com><!-- RSS Feeds --><link rel=alternate type=application/rss+xml title="Pankaj Parashar" href=/feed.xml><!-- Bing webmaster tools --><meta name=msvalidate.01 content=487AEF186C6F028EB596ABCAA4EF040B></head><!--
    ______           _         _  ______                   _
    | ___ \         | |       (_) | ___ \                 | |
    | |_/ /_ _ _ __ | | ____ _ _  | |_/ /_ _ _ __ __ _ ___| |__   __ _ _ __
    |  __/ _` | '_ \| |/ / _` | | |  __/ _` | '__/ _` / __| '_ \ / _` | '__|
    | | | (_| | | | |   < (_| | | | | | (_| | | | (_| \__ \ | | | (_| | |
    \_|  \__,_|_| |_|_|\_\__,_| | \_|  \__,_|_|  \__,_|___/_| |_|\__,_|_|
                             _/ |
                            |__/

    Giant ascii art embedded in every page of your site is how you
    show other people that YOU CARE. Mainly I care about developers,
    which is what I presume you are if you're all about viewing
    the source. Clearly you're my kind of person.

    This is v4, it's run through Jekyll, it's been fun to build,
    there's always more to do, and you may notice that aside from
    Google Analytics there is no JavaScript. None.

    That's one way of many you keep your pages fast. I care about
    keeping this site fast because your time is precious and I need
    to get out of your way.

    :: Pankaj Parashar

    --><body><!-- Microdata markup added by Google Structured Data Markup Helper. --><!--[if lt IE 8]>
            <p class="browsehappy">You are using an <strong>outdated</strong> browser. Please <a href="http://browsehappy.com/">upgrade your browser</a> to improve your experience.</p>
        <![endif]--><header role=banner><h1 class=header__title><a href="/" class=header__title--link itemprop=author itemscope itemtype=http://schema.org/Person>Pankaj Parashar</a></h1><h2 class=header__subtitle>Developer. Designer. Writer.</h2><a href=http://twitter.com/pankajparashar class=header__follow>Follow @pankajparashar<!--<span class="header__follow--about fa fa-stack-exchange"></span>--></a> <!--<div id="fusion_ad">
        <span class="fusionentire">
            <a href="http://adn.fusionads.net/click?creative_id=811&amp;publisher_id=229&amp;1313146590559.2966" title="New Relic - Live the nerd life. Get the t-shirt." target="_top">
                <img src="http://adn.fusionads.net/creatives/retina/811-nerdlife.png" class="fusionimg" alt="New Relic - Live the nerd life. Get the t-shirt." border="0" height="100" width="130" style="width: 130px;">
            </a>
            <a href="http://adn.fusionads.net/click?creative_id=811&amp;publisher_id=229&amp;1313146590559.2966" class="fusiontext" title="New Relic - Live the nerd life. Get the t-shirt." target="_top">New Relic - Live the nerd life. Get the t-shirt.</a>
        </span>
        <a href="http://fusionads.net" class="powered">Ad by Fusion</a>
    </div>
    --><p class=header__desc>Hello. I am 24yrs old frontend designer and web developer from <a href="https://maps.google.com/maps?q=mumbai,+india">Mumbai, India</a>.</p><p class=header__desc>Browse through some of my <a href=/projects>side-projects</a> or read the articles on my <a href="/">blog</a> here.</p><hr class=header__hr><p class=header__desc>Get notified to read new articles,</p><form accept-charset=UTF-8 action=https://www.sendicate.net/subscribe/2w3gcl method=post class=header__form target=_blank><input class=header__form--subscriber name=email type=email placeholder="Enter your email address + press enter..." autocomplete=off><a href=/feed.xml class=header__form--submit><!--<i class="fa fa-rss"></i>--></a></form></header><!-- More info on WAI-ARIA roles
             http://knowledge.onsubject.com/html-role-attributes/ --><section role=main><article><h2 class=post__title><a class=post__title--link href=/posts/download-the-web-with-wget>Download the web with WGET</a></h2><small class=post__date>Sunday, March 30, 2014</small> <small class=post__time>7.616666666666666</small><p class=post__excerpt>Having recently discovered the power of wget command, I have written this article to remind myself the various ways we could use this command to download the world wide web.</p><p>The name <code>wget</code> is derived from the amalgamation of <code>World Wide Web</code> and <code>Get</code>. The UNIX <a href=http://unixhelp.ed.ac.uk/CGI/man-cgi?wget>manual page</a> describes it as,</p><div class=highlight><pre><code class=sh><span class=nv>$ </span>man wget
GNU Wget is a free utility <span class=k>for </span>non-interactive download of files from
the Web. It supports HTTP, HTTPS, and FTP protocols, as well as retrieval
through HTTP proxies.
</code></pre></div><p>Wget can follow links in HTML and XHTML pages and create local versions of remote web sites, fully recreating the directory structure of the original site. The best part is that Wget respects the Robot Exclusion Standard <a href=/robots.txt>(/robots.txt)</a></p><p>The help page is good enough to explain all the available options that comes bundled with the <code>wget</code> package,</p><div class=highlight><pre><code class=sh>pankajparashar@macbook-pro: ~
<span class=nv>$ </span>wget -h
GNU Wget 1.14, a non-interactive network retriever.
Usage: wget <span class=o>[</span>OPTION<span class=o>]</span>... <span class=o>[</span>URL<span class=o>]</span>...

Mandatory arguments to long options are mandatory <span class=k>for </span>short options too.

Startup:
  -V,  --version           display the version of Wget and exit.
  -h,  --help              print this help.
  -b,  --background        go to background after startup.
  -e,  --execute<span class=o>=</span>COMMAND   execute a <span class=sb>`</span>.wgetrc<span class=s1>&#39;-style command.</span>

<span class=s1>Logging and input file:</span>
<span class=s1>  -o,  --output-file=FILE    log messages to FILE.</span>
<span class=s1>  -a,  --append-output=FILE  append messages to FILE.</span>
<span class=s1>  -q,  --quiet               quiet (no output).</span>
<span class=s1>  -v,  --verbose             be verbose (this is the default).</span>
<span class=s1>  -nv, --no-verbose          turn off verboseness, without being quiet.</span>
<span class=s1>       --report-speed=TYPE   Output bandwidth as TYPE.  TYPE can be bits.</span>
<span class=s1>  -i,  --input-file=FILE     download URLs found in local or external FILE.</span>
<span class=s1>  -F,  --force-html          treat input file as HTML.</span>
<span class=s1>  -B,  --base=URL            resolves HTML input-file links (-i -F)</span>
<span class=s1>                             relative to URL.</span>
<span class=s1>       --config=FILE         Specify config file to use.</span>

<span class=s1>Download:</span>
<span class=s1>  -t,  --tries=NUMBER            set number of retries to NUMBER (0 unlimits).</span>
<span class=s1>       --retry-connrefused       retry even if connection is refused.</span>
<span class=s1>  -O,  --output-document=FILE    write documents to FILE.</span>
<span class=s1>  -nc, --no-clobber              skip downloads that would download to</span>
<span class=s1>                                 existing files (overwriting them).</span>
<span class=s1>  -c,  --continue                resume getting a partially-downloaded file.</span>
<span class=s1>       --progress=TYPE           select progress gauge type.</span>
<span class=s1>  -N,  --timestamping            don&#39;</span>t re-retrieve files unless newer than
                                 local.
  --no-use-server-timestamps     don<span class=s1>&#39;t set the local file&#39;</span>s timestamp by
                                 the one on the server.
  -S,  --server-response         print server response.
       --spider                  don<span class=s1>&#39;t download anything.</span>
<span class=s1>  -T,  --timeout=SECONDS         set all timeout values to SECONDS.</span>
<span class=s1>       --dns-timeout=SECS        set the DNS lookup timeout to SECS.</span>
<span class=s1>       --connect-timeout=SECS    set the connect timeout to SECS.</span>
<span class=s1>       --read-timeout=SECS       set the read timeout to SECS.</span>
<span class=s1>  -w,  --wait=SECONDS            wait SECONDS between retrievals.</span>
<span class=s1>       --waitretry=SECONDS       wait 1..SECONDS between retries of a retrieval.</span>
<span class=s1>       --random-wait             wait from 0.5*WAIT...1.5*WAIT secs between retrievals.</span>
<span class=s1>       --no-proxy                explicitly turn off proxy.</span>
<span class=s1>  -Q,  --quota=NUMBER            set retrieval quota to NUMBER.</span>
<span class=s1>       --bind-address=ADDRESS    bind to ADDRESS (hostname or IP) on local host.</span>
<span class=s1>       --limit-rate=RATE         limit download rate to RATE.</span>
<span class=s1>       --no-dns-cache            disable caching DNS lookups.</span>
<span class=s1>       --restrict-file-names=OS  restrict chars in file names to ones OS allows.</span>
<span class=s1>       --ignore-case             ignore case when matching files/directories.</span>
<span class=s1>  -4,  --inet4-only              connect only to IPv4 addresses.</span>
<span class=s1>  -6,  --inet6-only              connect only to IPv6 addresses.</span>
<span class=s1>       --prefer-family=FAMILY    connect first to addresses of specified family,</span>
<span class=s1>                                 one of IPv6, IPv4, or none.</span>
<span class=s1>       --user=USER               set both ftp and http user to USER.</span>
<span class=s1>       --password=PASS           set both ftp and http password to PASS.</span>
<span class=s1>       --ask-password            prompt for passwords.</span>
<span class=s1>       --no-iri                  turn off IRI support.</span>
<span class=s1>       --local-encoding=ENC      use ENC as the local encoding for IRIs.</span>
<span class=s1>       --remote-encoding=ENC     use ENC as the default remote encoding.</span>
<span class=s1>       --unlink                  remove file before clobber.</span>

<span class=s1>Directories:</span>
<span class=s1>  -nd, --no-directories           don&#39;</span>t create directories.
  -x,  --force-directories        force creation of directories.
  -nH, --no-host-directories      don<span class=s1>&#39;t create host directories.</span>
<span class=s1>       --protocol-directories     use protocol name in directories.</span>
<span class=s1>  -P,  --directory-prefix=PREFIX  save files to PREFIX/...</span>
<span class=s1>       --cut-dirs=NUMBER          ignore NUMBER remote directory components.</span>

<span class=s1>HTTP options:</span>
<span class=s1>       --http-user=USER        set http user to USER.</span>
<span class=s1>       --http-password=PASS    set http password to PASS.</span>
<span class=s1>       --no-cache              disallow server-cached data.</span>
<span class=s1>       --default-page=NAME     Change the default page name (normally</span>
<span class=s1>                               this is `index.html&#39;</span>.<span class=o>)</span>.
  -E,  --adjust-extension      save HTML/CSS documents with proper extensions.
       --ignore-length         ignore <span class=sb>`</span>Content-Length<span class=s1>&#39; header field.</span>
<span class=s1>       --header=STRING         insert STRING among the headers.</span>
<span class=s1>       --max-redirect          maximum redirections allowed per page.</span>
<span class=s1>       --proxy-user=USER       set USER as proxy username.</span>
<span class=s1>       --proxy-password=PASS   set PASS as proxy password.</span>
<span class=s1>       --referer=URL           include `Referer: URL&#39;</span> header in HTTP request.
       --save-headers          save the HTTP headers to file.
  -U,  --user-agent<span class=o>=</span>AGENT      identify as AGENT instead of Wget/VERSION.
       --no-http-keep-alive    disable HTTP keep-alive <span class=o>(</span>persistent connections<span class=o>)</span>.
       --no-cookies            don<span class=s1>&#39;t use cookies.</span>
<span class=s1>       --load-cookies=FILE     load cookies from FILE before session.</span>
<span class=s1>       --save-cookies=FILE     save cookies to FILE after session.</span>
<span class=s1>       --keep-session-cookies  load and save session (non-permanent) cookies.</span>
<span class=s1>       --post-data=STRING      use the POST method; send STRING as the data.</span>
<span class=s1>       --post-file=FILE        use the POST method; send contents of FILE.</span>
<span class=s1>       --content-disposition   honor the Content-Disposition header when</span>
<span class=s1>                               choosing local file names (EXPERIMENTAL).</span>
<span class=s1>       --content-on-error      output the received content on server errors.</span>
<span class=s1>       --auth-no-challenge     send Basic HTTP authentication information</span>
<span class=s1>                               without first waiting for the server&#39;</span>s
                               challenge.

HTTPS <span class=o>(</span>SSL/TLS<span class=o>)</span> options:
       --secure-protocol<span class=o>=</span>PR     choose secure protocol, one of auto, SSLv2,
                                SSLv3, and TLSv1.
       --no-check-certificate   don<span class=s1>&#39;t validate the server&#39;</span>s certificate.
       --certificate<span class=o>=</span>FILE       client certificate file.
       --certificate-type<span class=o>=</span>TYPE  client certificate <span class=nb>type</span>, PEM or DER.
       --private-key<span class=o>=</span>FILE       private key file.
       --private-key-type<span class=o>=</span>TYPE  private key <span class=nb>type</span>, PEM or DER.
       --ca-certificate<span class=o>=</span>FILE    file with the bundle of CA<span class=s1>&#39;s.</span>
<span class=s1>       --ca-directory=DIR       directory where hash list of CA&#39;</span>s is stored.
       --random-file<span class=o>=</span>FILE       file with random data <span class=k>for </span>seeding the SSL PRNG.
       --egd-file<span class=o>=</span>FILE          file naming the EGD socket with random data.

FTP options:
       --ftp-user<span class=o>=</span>USER         <span class=nb>set </span>ftp user to USER.
       --ftp-password<span class=o>=</span>PASS     <span class=nb>set </span>ftp password to PASS.
       --no-remove-listing     don<span class=s1>&#39;t remove `.listing&#39;</span> files.
       --no-glob               turn off FTP file name globbing.
       --no-passive-ftp        disable the <span class=s2>&quot;passive&quot;</span> transfer mode.
       --preserve-permissions  preserve remote file permissions.
       --retr-symlinks         when recursing, get linked-to files <span class=o>(</span>not dir<span class=o>)</span>.

WARC options:
       --warc-file<span class=o>=</span>FILENAME      save request/response data to a .warc.gz file.
       --warc-header<span class=o>=</span>STRING      insert STRING into the warcinfo record.
       --warc-max-size<span class=o>=</span>NUMBER    <span class=nb>set </span>maximum size of WARC files to NUMBER.
       --warc-cdx                write CDX index files.
       --warc-dedup<span class=o>=</span>FILENAME     <span class=k>do </span>not store records listed in this CDX file.
       --no-warc-compression     <span class=k>do </span>not compress WARC files with GZIP.
       --no-warc-digests         <span class=k>do </span>not calculate SHA1 digests.
       --no-warc-keep-log        <span class=k>do </span>not store the log file in a WARC record.
       --warc-tempdir<span class=o>=</span>DIRECTORY  location <span class=k>for </span>temporary files created by the
                                 WARC writer.

Recursive download:
  -r,  --recursive          specify recursive download.
  -l,  --level<span class=o>=</span>NUMBER       maximum recursion depth <span class=o>(</span>inf or 0 <span class=k>for </span>infinite<span class=o>)</span>.
       --delete-after       delete files locally after downloading them.
  -k,  --convert-links      make links in downloaded HTML or CSS point to
                            <span class=nb>local </span>files.
  -K,  --backup-converted   before converting file X, back up as X.orig.
  -m,  --mirror             shortcut <span class=k>for</span> -N -r -l inf --no-remove-listing.
  -p,  --page-requisites    get all images, etc. needed to display HTML page.
       --strict-comments    turn on strict <span class=o>(</span>SGML<span class=o>)</span> handling of HTML comments.

Recursive accept/reject:
  -A,  --accept<span class=o>=</span>LIST               comma-separated list of accepted extensions.
  -R,  --reject<span class=o>=</span>LIST               comma-separated list of rejected extensions.
       --accept-regex<span class=o>=</span>REGEX        regex matching accepted URLs.
       --reject-regex<span class=o>=</span>REGEX        regex matching rejected URLs.
       --regex-type<span class=o>=</span>TYPE           regex <span class=nb>type</span> <span class=o>(</span>posix<span class=o>)</span>.
  -D,  --domains<span class=o>=</span>LIST              comma-separated list of accepted domains.
       --exclude-domains<span class=o>=</span>LIST      comma-separated list of rejected domains.
       --follow-ftp                follow FTP links from HTML documents.
       --follow-tags<span class=o>=</span>LIST          comma-separated list of followed HTML tags.
       --ignore-tags<span class=o>=</span>LIST          comma-separated list of ignored HTML tags.
  -H,  --span-hosts                go to foreign hosts when recursive.
  -L,  --relative                  follow relative links only.
  -I,  --include-directories<span class=o>=</span>LIST  list of allowed directories.
  --trust-server-names             use the name specified by the redirection
                                   url last component.
  -X,  --exclude-directories<span class=o>=</span>LIST  list of excluded directories.
  -np, --no-parent                 don<span class=err>&#39;</span>t ascend to the parent directory.
</code></pre></div><p>We'll go through the various use-cases and how to use wget commmand to accomplish basic tasks. For all the examples, we'll use the long format to specify the options, because they are verbose and self-explanatory.</p><p><strong>Download the index page of a website</strong><br>You can download the file located at the root of the url by simply specifying the website address.</p><div class=highlight><pre><code class=sh><span class=nv>$ </span>wget http://google.com
</code></pre></div><p>However, you would have no control over the name of the file downloaded in your local system.</p><p><strong>Download and save using a different filename</strong><br>Fortunately, wget allows to explicitly specify the name of the downloaded file, as shown below,</p><div class=highlight><pre><code class=sh><span class=nv>$ </span>wget --output-document<span class=o>=</span>index.html http://google.com
</code></pre></div><p><strong>Download the entire website</strong><br>If you want to clone the entire website and restrict the pages only to the specified domain for offline viewing, then wget has got you covered.</p><div class=highlight><pre><code class=sh><span class=nv>$ </span>wget <span class=se>\</span>
    --mirror <span class=se>\</span>
    --recursive <span class=se>\</span>
    --no-clobber <span class=se>\</span>
    --page-requisites <span class=se>\</span>
    --adjust-extension <span class=se>\</span>
    --convert-links <span class=se>\</span>
    --domains pankajparashar.com <span class=se>\</span>
    --no-parent <span class=se>\</span>
        pankajparashar.com
</code></pre></div><p>You could also specify the file extensions that you may/may not want to download by specifying the --accept=LIST or --reject=LIST appropriately.</p><p><strong>User-agent masking</strong><br>You can also simulate the download by explicitly specifying the user agent. Might be useful for websites that block download for few UAs</p><div class=highlight><pre><code class=sh><span class=nv>$ </span>wget --user-agent<span class=o>=</span>Mozilla http://google.com
</code></pre></div><p><strong>Download file via FTP url</strong></p><div class=highlight><pre><code class=sh><span class=c># Anonymous FTP</span>
<span class=nv>$ </span>wget ftp://cdn.pankajparashar.com/file.txt

<span class=c># FTP download using wget with username and password authentication.</span>
<span class=nv>$ </span>wget --ftp-user<span class=o>=</span>USERNAME --ftp-password<span class=o>=</span>PASSWORD ftp://cdn.pankajparashar.com/file.txt
</code></pre></div><p>Did you enjoy reading this article? I'd love to hear your thoughts. Shoot me an <a href=mailto:email@pankajparashar.com>email</a> or send me a <a href="https://twitter.com/intent/tweet?via=pankajparashar&text=Download the web with WGET">tweet</a> if you've got any comments.</p></article></section><footer role=contentinfo><input class=footer__search type=search placeholder="Search this website + press enter..." autocomplete=off role=search><p class=footer__copyright>&copy;2014. Pankaj Parashar. <a class=footer__top--link href=# role=button>Back to top</a></p></footer><script src=/js/script.9ae5.js></script></body></html>